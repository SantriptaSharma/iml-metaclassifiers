{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by cleaning the datasets by dropping null values, selecting our features, and encoding them as required. Further, to maintain a similar structure in all datasets, we move the label (predictor) to the last column.\n",
    "\n",
    "Prior to this, I've manually cleaned out the NAs from the aus_rain dataset (replacing them with nulls) and unwrapped the quotes(\") from around each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "! rmdir /S /Q datasets\n",
    "! mkdir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anemia\n",
      "aus_rain\n",
      "campusrecruitment\n",
      "employability\n",
      "fraud\n",
      "loan\n",
      "mobile_price\n",
      "stress\n",
      "student_testprep\n",
      "titanic\n",
      "wine\n",
      "drug\n",
      "shipping\n"
     ]
    }
   ],
   "source": [
    "F = {\n",
    "\t\"STD\": 0,\n",
    "\t\"DROP\": 1,\n",
    "\t\"LABEL\": 2,\n",
    "\t\"ONEHOT\": 3,\n",
    "\t\"DUMMY\": 4,\n",
    "\t\"RAW\": 5,\n",
    "}\n",
    "\n",
    "sets = {\n",
    "\t\"anemia\": [\n",
    "\t\tF[\"ONEHOT\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"RAW\"], F[\"RAW\"], F[\"STD\"], F[\"ONEHOT\"], F[\"DUMMY\"], F[\"DUMMY\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"DROP\"], F[\"DUMMY\"], F[\"STD\"], F[\"LABEL\"], F[\"DUMMY\"]\n",
    "\t],\n",
    "\t\"aus_rain\": [\n",
    "\t\tF[\"DROP\"], F[\"ONEHOT\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"ONEHOT\"], F[\"STD\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"DUMMY\"], F[\"LABEL\"]\n",
    "\t],\n",
    "\t\"campusrecruitment\": [\n",
    "\t\tF[\"DROP\"], F[\"ONEHOT\"], F[\"STD\"], F[\"ONEHOT\"], F[\"STD\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"STD\"], F[\"ONEHOT\"], F[\"DUMMY\"], F[\"STD\"], F[\"ONEHOT\"], F[\"STD\"], F[\"LABEL\"], F[\"DROP\"]\n",
    "\t],\n",
    "\t\"employability\": [F[\"DUMMY\"] for i in range(5)] + [F[\"LABEL\"]],\n",
    "\t\"fraud\": [F[\"DROP\"]] + [F[\"STD\"] for i in range(28)] + [F[\"STD\"], F[\"LABEL\"]],\n",
    "\t\"loan\": [\n",
    "\t\tF[\"DROP\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"DROP\"], F[\"STD\"], F[\"STD\"], F[\"RAW\"], F[\"STD\"], F[\"DUMMY\"], F[\"DUMMY\"], F[\"DUMMY\"], F[\"DUMMY\"], F[\"LABEL\"]\n",
    "\t],\n",
    "\t\"mobile_price\": [\n",
    "\t\tF[\"STD\"], F[\"DUMMY\"], F[\"STD\"], F[\"DUMMY\"], F[\"STD\"], F[\"DUMMY\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"DUMMY\"], F[\"DUMMY\"], F[\"DUMMY\"], F[\"LABEL\"]\n",
    "\t],\n",
    "\t\"stress\": [\n",
    "\t\tF[\"STD\"], F[\"STD\"], F[\"DUMMY\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"STD\"], F[\"LABEL\"]\n",
    "\t],\n",
    "\t\"student_testprep\": [\n",
    "\t\tF[\"DUMMY\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"LABEL\"], F[\"STD\"], F[\"STD\"], F[\"STD\"]\n",
    "\t],\n",
    "\t\"titanic\": [\n",
    "\t\tF[\"DROP\"], F[\"LABEL\"], F[\"ONEHOT\"], F[\"DUMMY\"], F[\"STD\"], F[\"RAW\"], F[\"RAW\"], F[\"STD\"], F[\"ONEHOT\"]\n",
    "\t],\n",
    "\t\"wine\": [F[\"LABEL\"]] + [F[\"STD\"] for i in range(13)],\n",
    "\t\"drug\": [\n",
    "\t\tF[\"STD\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"STD\"], F[\"LABEL\"]\n",
    "\t],\n",
    "\t\"shipping\": [\n",
    "\t\tF[\"DROP\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"RAW\"], F[\"RAW\"], F[\"STD\"], F[\"RAW\"], F[\"ONEHOT\"], F[\"ONEHOT\"], F[\"STD\"], F[\"STD\"], F[\"LABEL\"]\n",
    "\t]\n",
    "}\n",
    "\n",
    "assert(len(sets[\"anemia\"]) == 17)\n",
    "assert(len(sets[\"drug\"]) == 6)\n",
    "assert(len(sets[\"campusrecruitment\"]) == 15)\n",
    "assert(len(sets[\"employability\"]) == 6)\n",
    "assert(len(sets[\"fraud\"]) == 31)\n",
    "assert(len(sets[\"loan\"]) == 14)\n",
    "assert(len(sets[\"mobile_price\"]) == 21)\n",
    "assert(len(sets[\"shipping\"]) == 12)\n",
    "assert(len(sets[\"stress\"]) == 21)\n",
    "assert(len(sets[\"student_testprep\"]) == 8)\n",
    "assert(len(sets[\"titanic\"]) == 9)\n",
    "assert(len(sets[\"wine\"]) == 14)\n",
    "\n",
    "assert(len(sets) == 13)\n",
    "\n",
    "for k in sets:\n",
    "\tprint(k)\n",
    "\tc = 0\n",
    "\tfor i in sets[k]:\n",
    "\t\tif i == F[\"LABEL\"]:\n",
    "\t\t\tc += 1\n",
    "\tassert(c == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "def process_dataset(dataset):\n",
    "\tprint(f\"Processing {dataset}\")\n",
    "\tdf = pd.read_csv(f\"datasets_src/{dataset}/{dataset}.csv\")\n",
    "\n",
    "\tprint(f\"Before dropping columns: {df.shape}\")\n",
    "\t# Drop columns\n",
    "\tfor i, col in enumerate(df.columns):\n",
    "\t\tif sets[dataset][i] == F[\"DROP\"]:\n",
    "\t\t\tprint(f\"Dropping {i}: {col}\")\n",
    "\t\t\tdf = df.drop(columns=[col])\n",
    "\t\n",
    "\tprint(f\"After dropping columns: {df.shape}\")\n",
    "\n",
    "\tset = [i for i in sets[dataset] if i != F[\"DROP\"]]\n",
    "\n",
    "\t# Drop NA\n",
    "\tprint(f\"Before dropping NAs: {df.shape}\")\n",
    "\tdf = df.dropna()\n",
    "\tprint(f\"After dropping NAs: {df.shape}\")\n",
    "\n",
    "\t# Apply transformations\n",
    "\tfor i, col in enumerate(df.columns):\n",
    "\t\tmode = set[i]\n",
    "\n",
    "\t\tif mode == F[\"STD\"]:\n",
    "\t\t\tprint(f\"Standardising {i}: {col}\")\n",
    "\t\t\tdf[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "\t\telif mode == F[\"RAW\"]:\n",
    "\t\t\tprint(f\"Leaving {i}: {col} raw\")\n",
    "\n",
    "\tlabel_col = \"\"\n",
    "\tfor i, col in enumerate(df.columns):\n",
    "\t\tif set[i] == F[\"LABEL\"]:\n",
    "\t\t\tlabel_col = col\n",
    "\t\t\tbreak\n",
    "\n",
    "\tdf_caten = df.copy(deep = True)\n",
    "\tfor i, col in enumerate(df.columns):\n",
    "\t\tif set[i] == F[\"ONEHOT\"] or set[i] == F[\"DUMMY\"]:\n",
    "\t\t\tprint(f\"Categorizing {i}: {col}\")\n",
    "\t\t\tprint(f\"Before: {df_caten.shape}\")\n",
    "\t\t\tdf_caten = df_caten.drop(columns=[col])\n",
    "\t\t\tencoded = pd.get_dummies(df[col], prefix=col[:5])\n",
    "\t\t\tdf_caten = pd.concat([df_caten, encoded], axis = 1)\n",
    "\t\t\tprint(f\"After: {df_caten.shape}\")\n",
    "\t\t\tprint(f\"Categories: {encoded.columns} ({len(encoded.columns)})\")\n",
    "\n",
    "\n",
    "\tdf = df_caten\n",
    "\n",
    "\t# Encode label & move it down to the end\n",
    "\tprint(f\"Encoding label {label_col}\")\n",
    "\tle = LabelEncoder()\n",
    "\tdf[label_col] = le.fit_transform(df[label_col])\n",
    "\tdf = df[[c for c in df if c != label_col] + [label_col]]\n",
    "\t\n",
    "\n",
    "\tprint(f\"Before dropping incidental NAs: {df.shape}\")\n",
    "\tdf = df.dropna()\n",
    "\tprint(f\"After dropping incidental NAs: {df.shape}\")\n",
    "\tdf.to_csv(f\"datasets/{dataset}.csv\", index=False)\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1: anemia\n",
      "Processing anemia\n",
      "Before dropping columns: (33924, 17)\n",
      "Dropping 12: When child put to breast\n",
      "After dropping columns: (33924, 16)\n",
      "Before dropping NAs: (33924, 16)\n",
      "After dropping NAs: (9546, 16)\n",
      "Leaving 4: Births in last five years raw\n",
      "Leaving 5: Age of respondent at 1st birth raw\n",
      "Standardising 6: Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)\n",
      "Standardising 13: Hemoglobin level adjusted for altitude (g/dl - 1 decimal)\n",
      "Categorizing 0: Age in 5-year groups\n",
      "Before: (9546, 16)\n",
      "After: (9546, 22)\n",
      "Categories: Index(['Age i_15-19', 'Age i_20-24', 'Age i_25-29', 'Age i_30-34',\n",
      "       'Age i_35-39', 'Age i_40-44', 'Age i_45-49'],\n",
      "      dtype='object') (7)\n",
      "Categorizing 1: Type of place of residence\n",
      "Before: (9546, 22)\n",
      "After: (9546, 23)\n",
      "Categories: Index(['Type _Rural', 'Type _Urban'], dtype='object') (2)\n",
      "Categorizing 2: Highest educational level\n",
      "Before: (9546, 23)\n",
      "After: (9546, 26)\n",
      "Categories: Index(['Highe_Higher', 'Highe_No education', 'Highe_Primary',\n",
      "       'Highe_Secondary'],\n",
      "      dtype='object') (4)\n",
      "Categorizing 3: Wealth index combined\n",
      "Before: (9546, 26)\n",
      "After: (9546, 30)\n",
      "Categories: Index(['Wealt_Middle', 'Wealt_Poorer', 'Wealt_Poorest', 'Wealt_Richer',\n",
      "       'Wealt_Richest'],\n",
      "      dtype='object') (5)\n",
      "Categorizing 7: Anemia level\n",
      "Before: (9546, 30)\n",
      "After: (9546, 33)\n",
      "Categories: Index(['Anemi_Mild', 'Anemi_Moderate', 'Anemi_Not anemic', 'Anemi_Severe'], dtype='object') (4)\n",
      "Categorizing 8: Have mosquito bed net for sleeping (from household questionnaire)\n",
      "Before: (9546, 33)\n",
      "After: (9546, 34)\n",
      "Categories: Index(['Have _No', 'Have _Yes'], dtype='object') (2)\n",
      "Categorizing 9: Smokes cigarettes\n",
      "Before: (9546, 34)\n",
      "After: (9546, 35)\n",
      "Categories: Index(['Smoke_No', 'Smoke_Yes'], dtype='object') (2)\n",
      "Categorizing 10: Current marital status\n",
      "Before: (9546, 35)\n",
      "After: (9546, 36)\n",
      "Categories: Index(['Curre_Living with partner', 'Curre_Married'], dtype='object') (2)\n",
      "Categorizing 11: Currently residing with husband/partner\n",
      "Before: (9546, 36)\n",
      "After: (9546, 37)\n",
      "Categories: Index(['Curre_Living with her', 'Curre_Staying elsewhere'], dtype='object') (2)\n",
      "Categorizing 12: Had fever in last two weeks\n",
      "Before: (9546, 37)\n",
      "After: (9546, 39)\n",
      "Categories: Index(['Had f_Don't know', 'Had f_No', 'Had f_Yes'], dtype='object') (3)\n",
      "Categorizing 15: Taking iron pills, sprinkles or syrup\n",
      "Before: (9546, 39)\n",
      "After: (9546, 41)\n",
      "Categories: Index(['Takin_Don't know', 'Takin_No', 'Takin_Yes'], dtype='object') (3)\n",
      "Encoding label Anemia level.1\n",
      "Before dropping incidental NAs: (9546, 41)\n",
      "After dropping incidental NAs: (9546, 41)\n",
      "\n",
      "Set 2: aus_rain\n",
      "Processing aus_rain\n",
      "Before dropping columns: (145460, 23)\n",
      "Dropping 0: Date\n",
      "After dropping columns: (145460, 22)\n",
      "Before dropping NAs: (145460, 22)\n",
      "After dropping NAs: (56420, 22)\n",
      "Standardising 1: MinTemp\n",
      "Standardising 2: MaxTemp\n",
      "Standardising 3: Rainfall\n",
      "Standardising 4: Evaporation\n",
      "Standardising 5: Sunshine\n",
      "Standardising 7: WindGustSpeed\n",
      "Standardising 10: WindSpeed9am\n",
      "Standardising 11: WindSpeed3pm\n",
      "Standardising 12: Humidity9am\n",
      "Standardising 13: Humidity3pm\n",
      "Standardising 14: Pressure9am\n",
      "Standardising 15: Pressure3pm\n",
      "Standardising 16: Cloud9am\n",
      "Standardising 17: Cloud3pm\n",
      "Standardising 18: Temp9am\n",
      "Standardising 19: Temp3pm\n",
      "Categorizing 0: Location\n",
      "Before: (56420, 22)\n",
      "After: (56420, 47)\n",
      "Categories: Index(['Locat_AliceSprings', 'Locat_Brisbane', 'Locat_Cairns',\n",
      "       'Locat_Canberra', 'Locat_Cobar', 'Locat_CoffsHarbour', 'Locat_Darwin',\n",
      "       'Locat_Hobart', 'Locat_Melbourne', 'Locat_MelbourneAirport',\n",
      "       'Locat_Mildura', 'Locat_Moree', 'Locat_MountGambier',\n",
      "       'Locat_NorfolkIsland', 'Locat_Nuriootpa', 'Locat_Perth',\n",
      "       'Locat_PerthAirport', 'Locat_Portland', 'Locat_Sale', 'Locat_Sydney',\n",
      "       'Locat_SydneyAirport', 'Locat_Townsville', 'Locat_WaggaWagga',\n",
      "       'Locat_Watsonia', 'Locat_Williamtown', 'Locat_Woomera'],\n",
      "      dtype='object') (26)\n",
      "Categorizing 6: WindGustDir\n",
      "Before: (56420, 47)\n",
      "After: (56420, 62)\n",
      "Categories: Index(['WindG_E', 'WindG_ENE', 'WindG_ESE', 'WindG_N', 'WindG_NE', 'WindG_NNE',\n",
      "       'WindG_NNW', 'WindG_NW', 'WindG_S', 'WindG_SE', 'WindG_SSE',\n",
      "       'WindG_SSW', 'WindG_SW', 'WindG_W', 'WindG_WNW', 'WindG_WSW'],\n",
      "      dtype='object') (16)\n",
      "Categorizing 8: WindDir9am\n",
      "Before: (56420, 62)\n",
      "After: (56420, 77)\n",
      "Categories: Index(['WindD_E', 'WindD_ENE', 'WindD_ESE', 'WindD_N', 'WindD_NE', 'WindD_NNE',\n",
      "       'WindD_NNW', 'WindD_NW', 'WindD_S', 'WindD_SE', 'WindD_SSE',\n",
      "       'WindD_SSW', 'WindD_SW', 'WindD_W', 'WindD_WNW', 'WindD_WSW'],\n",
      "      dtype='object') (16)\n",
      "Categorizing 9: WindDir3pm\n",
      "Before: (56420, 77)\n",
      "After: (56420, 92)\n",
      "Categories: Index(['WindD_E', 'WindD_ENE', 'WindD_ESE', 'WindD_N', 'WindD_NE', 'WindD_NNE',\n",
      "       'WindD_NNW', 'WindD_NW', 'WindD_S', 'WindD_SE', 'WindD_SSE',\n",
      "       'WindD_SSW', 'WindD_SW', 'WindD_W', 'WindD_WNW', 'WindD_WSW'],\n",
      "      dtype='object') (16)\n",
      "Categorizing 20: RainToday\n",
      "Before: (56420, 92)\n",
      "After: (56420, 93)\n",
      "Categories: Index(['RainT_No', 'RainT_Yes'], dtype='object') (2)\n",
      "Encoding label RainTomorrow\n",
      "Before dropping incidental NAs: (56420, 125)\n",
      "After dropping incidental NAs: (56420, 125)\n",
      "\n",
      "Set 3: campusrecruitment\n",
      "Processing campusrecruitment\n",
      "Before dropping columns: (215, 15)\n",
      "Dropping 0: sl_no\n",
      "Dropping 14: salary\n",
      "After dropping columns: (215, 13)\n",
      "Before dropping NAs: (215, 13)\n",
      "After dropping NAs: (215, 13)\n",
      "Standardising 1: ssc_p\n",
      "Standardising 3: hsc_p\n",
      "Standardising 6: degree_p\n",
      "Standardising 9: etest_p\n",
      "Standardising 11: mba_p\n",
      "Categorizing 0: gender\n",
      "Before: (215, 13)\n",
      "After: (215, 14)\n",
      "Categories: Index(['gende_F', 'gende_M'], dtype='object') (2)\n",
      "Categorizing 2: ssc_b\n",
      "Before: (215, 14)\n",
      "After: (215, 15)\n",
      "Categories: Index(['ssc_b_Central', 'ssc_b_Others'], dtype='object') (2)\n",
      "Categorizing 4: hsc_b\n",
      "Before: (215, 15)\n",
      "After: (215, 16)\n",
      "Categories: Index(['hsc_b_Central', 'hsc_b_Others'], dtype='object') (2)\n",
      "Categorizing 5: hsc_s\n",
      "Before: (215, 16)\n",
      "After: (215, 18)\n",
      "Categories: Index(['hsc_s_Arts', 'hsc_s_Commerce', 'hsc_s_Science'], dtype='object') (3)\n",
      "Categorizing 7: degree_t\n",
      "Before: (215, 18)\n",
      "After: (215, 20)\n",
      "Categories: Index(['degre_Comm&Mgmt', 'degre_Others', 'degre_Sci&Tech'], dtype='object') (3)\n",
      "Categorizing 8: workex\n",
      "Before: (215, 20)\n",
      "After: (215, 21)\n",
      "Categories: Index(['worke_No', 'worke_Yes'], dtype='object') (2)\n",
      "Categorizing 10: specialisation\n",
      "Before: (215, 21)\n",
      "After: (215, 22)\n",
      "Categories: Index(['speci_Mkt&Fin', 'speci_Mkt&HR'], dtype='object') (2)\n",
      "Encoding label status\n",
      "Before dropping incidental NAs: (215, 22)\n",
      "After dropping incidental NAs: (215, 22)\n",
      "\n",
      "Set 4: employability\n",
      "Processing employability\n",
      "Before dropping columns: (829, 6)\n",
      "After dropping columns: (829, 6)\n",
      "Before dropping NAs: (829, 6)\n",
      "After dropping NAs: (829, 6)\n",
      "Categorizing 0: Gender\n",
      "Before: (829, 6)\n",
      "After: (829, 7)\n",
      "Categories: Index(['Gende_0', 'Gende_1'], dtype='object') (2)\n",
      "Categorizing 1: Education\n",
      "Before: (829, 7)\n",
      "After: (829, 8)\n",
      "Categories: Index(['Educa_0', 'Educa_1'], dtype='object') (2)\n",
      "Categorizing 2: Work Exp\n",
      "Before: (829, 8)\n",
      "After: (829, 9)\n",
      "Categories: Index(['Work _0', 'Work _1'], dtype='object') (2)\n",
      "Categorizing 3: Programming Exp\n",
      "Before: (829, 9)\n",
      "After: (829, 10)\n",
      "Categories: Index(['Progr_0', 'Progr_1'], dtype='object') (2)\n",
      "Categorizing 4: Matching\n",
      "Before: (829, 10)\n",
      "After: (829, 11)\n",
      "Categories: Index(['Match_0', 'Match_1'], dtype='object') (2)\n",
      "Encoding label Status\n",
      "Before dropping incidental NAs: (829, 11)\n",
      "After dropping incidental NAs: (829, 11)\n",
      "\n",
      "Set 5: fraud\n",
      "Processing fraud\n",
      "Before dropping columns: (568630, 31)\n",
      "Dropping 0: id\n",
      "After dropping columns: (568630, 30)\n",
      "Before dropping NAs: (568630, 30)\n",
      "After dropping NAs: (568630, 30)\n",
      "Standardising 0: V1\n",
      "Standardising 1: V2\n",
      "Standardising 2: V3\n",
      "Standardising 3: V4\n",
      "Standardising 4: V5\n",
      "Standardising 5: V6\n",
      "Standardising 6: V7\n",
      "Standardising 7: V8\n",
      "Standardising 8: V9\n",
      "Standardising 9: V10\n",
      "Standardising 10: V11\n",
      "Standardising 11: V12\n",
      "Standardising 12: V13\n",
      "Standardising 13: V14\n",
      "Standardising 14: V15\n",
      "Standardising 15: V16\n",
      "Standardising 16: V17\n",
      "Standardising 17: V18\n",
      "Standardising 18: V19\n",
      "Standardising 19: V20\n",
      "Standardising 20: V21\n",
      "Standardising 21: V22\n",
      "Standardising 22: V23\n",
      "Standardising 23: V24\n",
      "Standardising 24: V25\n",
      "Standardising 25: V26\n",
      "Standardising 26: V27\n",
      "Standardising 27: V28\n",
      "Standardising 28: Amount\n",
      "Encoding label Class\n",
      "Before dropping incidental NAs: (568630, 30)\n",
      "After dropping incidental NAs: (568630, 30)\n",
      "\n",
      "Set 6: loan\n",
      "Processing loan\n",
      "Before dropping columns: (5000, 14)\n",
      "Dropping 0: ID\n",
      "Dropping 4: ZIP.Code\n",
      "After dropping columns: (5000, 12)\n",
      "Before dropping NAs: (5000, 12)\n",
      "After dropping NAs: (5000, 12)\n",
      "Standardising 0: Age\n",
      "Standardising 1: Experience\n",
      "Standardising 2: Income\n",
      "Standardising 3: Family\n",
      "Standardising 4: CCAvg\n",
      "Leaving 5: Education raw\n",
      "Standardising 6: Mortgage\n",
      "Categorizing 7: Personal.Loan\n",
      "Before: (5000, 12)\n",
      "After: (5000, 13)\n",
      "Categories: Index(['Perso_0', 'Perso_1'], dtype='object') (2)\n",
      "Categorizing 8: Securities.Account\n",
      "Before: (5000, 13)\n",
      "After: (5000, 14)\n",
      "Categories: Index(['Secur_0', 'Secur_1'], dtype='object') (2)\n",
      "Categorizing 9: CD.Account\n",
      "Before: (5000, 14)\n",
      "After: (5000, 15)\n",
      "Categories: Index(['CD.Ac_0', 'CD.Ac_1'], dtype='object') (2)\n",
      "Categorizing 10: Online\n",
      "Before: (5000, 15)\n",
      "After: (5000, 16)\n",
      "Categories: Index(['Onlin_0', 'Onlin_1'], dtype='object') (2)\n",
      "Encoding label CreditCard\n",
      "Before dropping incidental NAs: (5000, 16)\n",
      "After dropping incidental NAs: (5000, 16)\n",
      "\n",
      "Set 7: mobile_price\n",
      "Processing mobile_price\n",
      "Before dropping columns: (2000, 21)\n",
      "After dropping columns: (2000, 21)\n",
      "Before dropping NAs: (2000, 21)\n",
      "After dropping NAs: (2000, 21)\n",
      "Standardising 0: battery_power\n",
      "Standardising 2: clock_speed\n",
      "Standardising 4: fc\n",
      "Standardising 6: int_memory\n",
      "Standardising 7: m_dep\n",
      "Standardising 8: mobile_wt\n",
      "Standardising 9: n_cores\n",
      "Standardising 10: pc\n",
      "Standardising 11: px_height\n",
      "Standardising 12: px_width\n",
      "Standardising 13: ram\n",
      "Standardising 14: sc_h\n",
      "Standardising 15: sc_w\n",
      "Standardising 16: talk_time\n",
      "Categorizing 1: blue\n",
      "Before: (2000, 21)\n",
      "After: (2000, 22)\n",
      "Categories: Index(['blue_0', 'blue_1'], dtype='object') (2)\n",
      "Categorizing 3: dual_sim\n",
      "Before: (2000, 22)\n",
      "After: (2000, 23)\n",
      "Categories: Index(['dual__0', 'dual__1'], dtype='object') (2)\n",
      "Categorizing 5: four_g\n",
      "Before: (2000, 23)\n",
      "After: (2000, 24)\n",
      "Categories: Index(['four__0', 'four__1'], dtype='object') (2)\n",
      "Categorizing 17: three_g\n",
      "Before: (2000, 24)\n",
      "After: (2000, 25)\n",
      "Categories: Index(['three_0', 'three_1'], dtype='object') (2)\n",
      "Categorizing 18: touch_screen\n",
      "Before: (2000, 25)\n",
      "After: (2000, 26)\n",
      "Categories: Index(['touch_0', 'touch_1'], dtype='object') (2)\n",
      "Categorizing 19: wifi\n",
      "Before: (2000, 26)\n",
      "After: (2000, 27)\n",
      "Categories: Index(['wifi_0', 'wifi_1'], dtype='object') (2)\n",
      "Encoding label price_range\n",
      "Before dropping incidental NAs: (2000, 27)\n",
      "After dropping incidental NAs: (2000, 27)\n",
      "\n",
      "Set 8: stress\n",
      "Processing stress\n",
      "Before dropping columns: (1100, 21)\n",
      "After dropping columns: (1100, 21)\n",
      "Before dropping NAs: (1100, 21)\n",
      "After dropping NAs: (1100, 21)\n",
      "Standardising 0: anxiety_level\n",
      "Standardising 1: self_esteem\n",
      "Standardising 3: depression\n",
      "Standardising 4: headache\n",
      "Standardising 5: blood_pressure\n",
      "Standardising 6: sleep_quality\n",
      "Standardising 7: breathing_problem\n",
      "Standardising 8: noise_level\n",
      "Standardising 9: living_conditions\n",
      "Standardising 10: safety\n",
      "Standardising 11: basic_needs\n",
      "Standardising 12: academic_performance\n",
      "Standardising 13: study_load\n",
      "Standardising 14: teacher_student_relationship\n",
      "Standardising 15: future_career_concerns\n",
      "Standardising 16: social_support\n",
      "Standardising 17: peer_pressure\n",
      "Standardising 18: extracurricular_activities\n",
      "Standardising 19: bullying\n",
      "Categorizing 2: mental_health_history\n",
      "Before: (1100, 21)\n",
      "After: (1100, 22)\n",
      "Categories: Index(['menta_0', 'menta_1'], dtype='object') (2)\n",
      "Encoding label stress_level\n",
      "Before dropping incidental NAs: (1100, 22)\n",
      "After dropping incidental NAs: (1100, 22)\n",
      "\n",
      "Set 9: student_testprep\n",
      "Processing student_testprep\n",
      "Before dropping columns: (1000, 8)\n",
      "After dropping columns: (1000, 8)\n",
      "Before dropping NAs: (1000, 8)\n",
      "After dropping NAs: (1000, 8)\n",
      "Standardising 5: math score\n",
      "Standardising 6: reading score\n",
      "Standardising 7: writing score\n",
      "Categorizing 0: gender\n",
      "Before: (1000, 8)\n",
      "After: (1000, 9)\n",
      "Categories: Index(['gende_female', 'gende_male'], dtype='object') (2)\n",
      "Categorizing 1: race/ethnicity\n",
      "Before: (1000, 9)\n",
      "After: (1000, 13)\n",
      "Categories: Index(['race/_group A', 'race/_group B', 'race/_group C', 'race/_group D',\n",
      "       'race/_group E'],\n",
      "      dtype='object') (5)\n",
      "Categorizing 2: parental level of education\n",
      "Before: (1000, 13)\n",
      "After: (1000, 18)\n",
      "Categories: Index(['paren_associate's degree', 'paren_bachelor's degree',\n",
      "       'paren_high school', 'paren_master's degree', 'paren_some college',\n",
      "       'paren_some high school'],\n",
      "      dtype='object') (6)\n",
      "Categorizing 3: lunch\n",
      "Before: (1000, 18)\n",
      "After: (1000, 19)\n",
      "Categories: Index(['lunch_free/reduced', 'lunch_standard'], dtype='object') (2)\n",
      "Encoding label test preparation course\n",
      "Before dropping incidental NAs: (1000, 19)\n",
      "After dropping incidental NAs: (1000, 19)\n",
      "\n",
      "Set 10: titanic\n",
      "Processing titanic\n",
      "Before dropping columns: (889, 9)\n",
      "Dropping 0: PassengerId\n",
      "After dropping columns: (889, 8)\n",
      "Before dropping NAs: (889, 8)\n",
      "After dropping NAs: (889, 8)\n",
      "Standardising 3: Age\n",
      "Leaving 4: SibSp raw\n",
      "Leaving 5: Parch raw\n",
      "Standardising 6: Fare\n",
      "Categorizing 1: Pclass\n",
      "Before: (889, 8)\n",
      "After: (889, 10)\n",
      "Categories: Index(['Pclas_1', 'Pclas_2', 'Pclas_3'], dtype='object') (3)\n",
      "Categorizing 2: Sex\n",
      "Before: (889, 10)\n",
      "After: (889, 11)\n",
      "Categories: Index(['Sex_Male', 'Sex_female'], dtype='object') (2)\n",
      "Categorizing 7: Embarked\n",
      "Before: (889, 11)\n",
      "After: (889, 13)\n",
      "Categories: Index(['Embar_1', 'Embar_2', 'Embar_3'], dtype='object') (3)\n",
      "Encoding label Survived\n",
      "Before dropping incidental NAs: (889, 13)\n",
      "After dropping incidental NAs: (889, 13)\n",
      "\n",
      "Set 11: wine\n",
      "Processing wine\n",
      "Before dropping columns: (178, 14)\n",
      "After dropping columns: (178, 14)\n",
      "Before dropping NAs: (178, 14)\n",
      "After dropping NAs: (178, 14)\n",
      "Standardising 1: alcohol\n",
      "Standardising 2: malic acid\n",
      "Standardising 3: ash\n",
      "Standardising 4: alcalinity of ash\n",
      "Standardising 5: magnesium\n",
      "Standardising 6: total phenols\n",
      "Standardising 7: flavanoids\n",
      "Standardising 8: nonflavanoid phenols\n",
      "Standardising 9: proanthocyanins\n",
      "Standardising 10: color intensity\n",
      "Standardising 11: hue\n",
      "Standardising 12: OD280/OD315 of diluted wines\n",
      "Standardising 13: proline\n",
      "Encoding label label\n",
      "Before dropping incidental NAs: (178, 14)\n",
      "After dropping incidental NAs: (178, 14)\n",
      "\n",
      "Set 12: drug\n",
      "Processing drug\n",
      "Before dropping columns: (200, 6)\n",
      "After dropping columns: (200, 6)\n",
      "Before dropping NAs: (200, 6)\n",
      "After dropping NAs: (200, 6)\n",
      "Standardising 0: Age\n",
      "Standardising 4: Na_to_K\n",
      "Categorizing 1: Sex\n",
      "Before: (200, 6)\n",
      "After: (200, 7)\n",
      "Categories: Index(['Sex_F', 'Sex_M'], dtype='object') (2)\n",
      "Categorizing 2: BP\n",
      "Before: (200, 7)\n",
      "After: (200, 9)\n",
      "Categories: Index(['BP_HIGH', 'BP_LOW', 'BP_NORMAL'], dtype='object') (3)\n",
      "Categorizing 3: Cholesterol\n",
      "Before: (200, 9)\n",
      "After: (200, 10)\n",
      "Categories: Index(['Chole_HIGH', 'Chole_NORMAL'], dtype='object') (2)\n",
      "Encoding label Drug\n",
      "Before dropping incidental NAs: (200, 10)\n",
      "After dropping incidental NAs: (200, 10)\n",
      "\n",
      "Set 13: shipping\n",
      "Processing shipping\n",
      "Before dropping columns: (10999, 12)\n",
      "Dropping 0: ID\n",
      "After dropping columns: (10999, 11)\n",
      "Before dropping NAs: (10999, 11)\n",
      "After dropping NAs: (10999, 11)\n",
      "Leaving 2: Customer_care_calls raw\n",
      "Leaving 3: Customer_rating raw\n",
      "Standardising 4: Cost_of_the_Product\n",
      "Leaving 5: Prior_purchases raw\n",
      "Standardising 8: Discount_offered\n",
      "Standardising 9: Weight_in_gms\n",
      "Categorizing 0: Warehouse_block\n",
      "Before: (10999, 11)\n",
      "After: (10999, 15)\n",
      "Categories: Index(['Wareh_A', 'Wareh_B', 'Wareh_C', 'Wareh_D', 'Wareh_F'], dtype='object') (5)\n",
      "Categorizing 1: Mode_of_Shipment\n",
      "Before: (10999, 15)\n",
      "After: (10999, 17)\n",
      "Categories: Index(['Mode__Flight', 'Mode__Road', 'Mode__Ship'], dtype='object') (3)\n",
      "Categorizing 6: Product_importance\n",
      "Before: (10999, 17)\n",
      "After: (10999, 19)\n",
      "Categories: Index(['Produ_high', 'Produ_low', 'Produ_medium'], dtype='object') (3)\n",
      "Categorizing 7: Gender\n",
      "Before: (10999, 19)\n",
      "After: (10999, 20)\n",
      "Categories: Index(['Gende_F', 'Gende_M'], dtype='object') (2)\n",
      "Encoding label Reached.on.Time_Y.N\n",
      "Before dropping incidental NAs: (10999, 20)\n",
      "After dropping incidental NAs: (10999, 20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(sets):\n",
    "\tprint(f\"Set {i + 1}: {name}\")\n",
    "\tprocess_dataset(name)\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Meta-Features for each Dataset (as defined in $\\verb|metafeatures.txt|$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datapoints</th>\n",
       "      <th>feats</th>\n",
       "      <th>numeric</th>\n",
       "      <th>avg_corr</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>num_to_cat_ratio</th>\n",
       "      <th>classes</th>\n",
       "      <th>majority_fraction</th>\n",
       "      <th>best_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anemia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aus_rain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campusrecruitment</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employability</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_price</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stress</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_testprep</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titanic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shipping</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datapoints  feats  numeric  avg_corr  n_binary  \\\n",
       "anemia                    0.0    0.0      0.0       0.0       0.0   \n",
       "aus_rain                  0.0    0.0      0.0       0.0       0.0   \n",
       "campusrecruitment         0.0    0.0      0.0       0.0       0.0   \n",
       "employability             0.0    0.0      0.0       0.0       0.0   \n",
       "fraud                     0.0    0.0      0.0       0.0       0.0   \n",
       "loan                      0.0    0.0      0.0       0.0       0.0   \n",
       "mobile_price              0.0    0.0      0.0       0.0       0.0   \n",
       "stress                    0.0    0.0      0.0       0.0       0.0   \n",
       "student_testprep          0.0    0.0      0.0       0.0       0.0   \n",
       "titanic                   0.0    0.0      0.0       0.0       0.0   \n",
       "wine                      0.0    0.0      0.0       0.0       0.0   \n",
       "drug                      0.0    0.0      0.0       0.0       0.0   \n",
       "shipping                  0.0    0.0      0.0       0.0       0.0   \n",
       "\n",
       "                   num_to_cat_ratio  classes  majority_fraction  \\\n",
       "anemia                          0.0      0.0                0.0   \n",
       "aus_rain                        0.0      0.0                0.0   \n",
       "campusrecruitment               0.0      0.0                0.0   \n",
       "employability                   0.0      0.0                0.0   \n",
       "fraud                           0.0      0.0                0.0   \n",
       "loan                            0.0      0.0                0.0   \n",
       "mobile_price                    0.0      0.0                0.0   \n",
       "stress                          0.0      0.0                0.0   \n",
       "student_testprep                0.0      0.0                0.0   \n",
       "titanic                         0.0      0.0                0.0   \n",
       "wine                            0.0      0.0                0.0   \n",
       "drug                            0.0      0.0                0.0   \n",
       "shipping                        0.0      0.0                0.0   \n",
       "\n",
       "                   best_classifier  \n",
       "anemia                         0.0  \n",
       "aus_rain                       0.0  \n",
       "campusrecruitment              0.0  \n",
       "employability                  0.0  \n",
       "fraud                          0.0  \n",
       "loan                           0.0  \n",
       "mobile_price                   0.0  \n",
       "stress                         0.0  \n",
       "student_testprep               0.0  \n",
       "titanic                        0.0  \n",
       "wine                           0.0  \n",
       "drug                           0.0  \n",
       "shipping                       0.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_feats = pd.DataFrame(columns=[\"datapoints\",\"feats\",\"numeric\",\"avg_corr\",\"n_binary\",\"num_to_cat_ratio\",\"classes\",\"majority_fraction\",\"best_classifier\"], index=sets.keys(), data=0.0)\n",
    "\n",
    "meta_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets, the first few cell blocks reload these, wasting time\n",
    "\n",
    "def load(dataset):\n",
    "\tdf = pd.read_csv(f\"datasets/{dataset}.csv\")\n",
    "\treturn df\n",
    "\n",
    "datasets = {\n",
    "\tk: load(k) for k in sets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, data in datasets.items():\n",
    "\tmeta_feats.loc[name, \"datapoints\"] = len(data)\n",
    "\tmeta_feats.loc[name, \"feats\"] = len(data.columns) - 1\n",
    "\tX = data.iloc[:, :-1]\n",
    "\ty = data.iloc[:, -1]\n",
    "\t\n",
    "\tnum, cat = len(X.select_dtypes(include=np.number).columns), len(X.select_dtypes(include=np.bool_).columns)\n",
    "\t\n",
    "\tmeta_feats.loc[name, \"numeric\"] = num\n",
    "\tmeta_feats.loc[name, \"n_binary\"] = cat\n",
    "\tassert(num + cat == len(X.columns))\n",
    "\n",
    "\t# laplace smoothing\n",
    "\tmeta_feats.loc[name, \"num_to_cat_ratio\"] = num / (cat+1)\n",
    "\n",
    "\tX = X.select_dtypes(include=np.number).to_numpy()\n",
    "\n",
    "\tC = np.corrcoef(X, rowvar=False)\n",
    "\n",
    "\tavg = 0.0\n",
    "\tfor i in range(len(C)):\n",
    "\t\t# ignore diagonal entries\n",
    "\t\t# symmetric, so only need to look at half\n",
    "\t\tfor j in range(i):\n",
    "\t\t\t# doesn't matter whether -ve or +ve linear correlation\n",
    "\t\t\tavg += abs(C[i, j])\n",
    "\n",
    "\t# non-diag entries = n^2 - n = n(n-1)\n",
    "\t# symmetric, so divide by 2\n",
    "\tif len(C) > 1:\n",
    "\t\tavg /= len(C) * (len(C) - 1) / 2\n",
    "\telse:\n",
    "\t\tavg = 0.0\n",
    "\n",
    "\tmeta_feats.loc[name, \"avg_corr\"] = avg\n",
    "\n",
    "\tmeta_feats.loc[name, \"classes\"] = len(np.unique(y))\n",
    "\n",
    "\tmeta_feats.loc[name, \"majority_fraction\"] = np.max(np.unique(y, return_counts=True)[1]) / len(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datapoints</th>\n",
       "      <th>feats</th>\n",
       "      <th>numeric</th>\n",
       "      <th>avg_corr</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>num_to_cat_ratio</th>\n",
       "      <th>classes</th>\n",
       "      <th>majority_fraction</th>\n",
       "      <th>best_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anemia</th>\n",
       "      <td>9546.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aus_rain</th>\n",
       "      <td>56420.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.286451</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.146789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.779741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campusrecruitment</th>\n",
       "      <td>215.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.357938</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employability</th>\n",
       "      <td>829.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.687575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud</th>\n",
       "      <td>568630.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.236221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_price</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stress</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.568837</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.339091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_testprep</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.850244</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titanic</th>\n",
       "      <td>889.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.194706</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.617548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>178.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.304957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug</th>\n",
       "      <td>200.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shipping</th>\n",
       "      <td>10999.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.131509</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.596691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datapoints  feats  numeric  avg_corr  n_binary  \\\n",
       "anemia                 9546.0   40.0      4.0  0.081748      36.0   \n",
       "aus_rain              56420.0  124.0     16.0  0.286451     108.0   \n",
       "campusrecruitment       215.0   21.0      5.0  0.357938      16.0   \n",
       "employability           829.0   10.0      0.0  0.000000      10.0   \n",
       "fraud                568630.0   29.0     29.0  0.236221       0.0   \n",
       "loan                   5000.0   15.0      7.0  0.145074       8.0   \n",
       "mobile_price           2000.0   26.0     14.0  0.034483      12.0   \n",
       "stress                 1100.0   21.0     19.0  0.568837       2.0   \n",
       "student_testprep       1000.0   18.0      3.0  0.850244      15.0   \n",
       "titanic                 889.0   12.0      4.0  0.194706       8.0   \n",
       "wine                    178.0   13.0     13.0  0.304957       0.0   \n",
       "drug                    200.0    9.0      2.0  0.063119       7.0   \n",
       "shipping              10999.0   19.0      6.0  0.131509      13.0   \n",
       "\n",
       "                   num_to_cat_ratio  classes  majority_fraction  \\\n",
       "anemia                     0.108108      4.0           0.386235   \n",
       "aus_rain                   0.146789      2.0           0.779741   \n",
       "campusrecruitment          0.294118      2.0           0.688372   \n",
       "employability              0.000000      2.0           0.687575   \n",
       "fraud                     29.000000      2.0           0.500000   \n",
       "loan                       0.777778      2.0           0.706000   \n",
       "mobile_price               1.076923      4.0           0.250000   \n",
       "stress                     6.333333      3.0           0.339091   \n",
       "student_testprep           0.187500      2.0           0.656000   \n",
       "titanic                    0.444444      2.0           0.617548   \n",
       "wine                      13.000000      3.0           0.398876   \n",
       "drug                       0.250000      5.0           0.455000   \n",
       "shipping                   0.428571      2.0           0.596691   \n",
       "\n",
       "                   best_classifier  \n",
       "anemia                         0.0  \n",
       "aus_rain                       0.0  \n",
       "campusrecruitment              0.0  \n",
       "employability                  0.0  \n",
       "fraud                          0.0  \n",
       "loan                           0.0  \n",
       "mobile_price                   0.0  \n",
       "stress                         0.0  \n",
       "student_testprep               0.0  \n",
       "titanic                        0.0  \n",
       "wine                           0.0  \n",
       "drug                           0.0  \n",
       "shipping                       0.0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess this data\n",
    "\n",
    "I normalise datapoints, feats, numeric, n_binary to the [0, 1] range by rescaling between min/max. I prefer normalisation here due to the abnormal/unpredictable (non-normal) distribution of these features as well as the similar unit/scale (counts)\n",
    "\n",
    "I leave classes raw, since the range is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "meta_feats.iloc[:, [0, 1, 2, 4]] = minmax_scale(meta_feats.iloc[:, [0, 1, 2, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datapoints</th>\n",
       "      <th>feats</th>\n",
       "      <th>numeric</th>\n",
       "      <th>avg_corr</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>num_to_cat_ratio</th>\n",
       "      <th>classes</th>\n",
       "      <th>majority_fraction</th>\n",
       "      <th>best_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anemia</th>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aus_rain</th>\n",
       "      <td>0.098939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.286451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.779741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campusrecruitment</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.357938</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employability</th>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.687575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_price</th>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.147826</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stress</th>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.568837</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.339091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_testprep</th>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.078261</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.850244</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titanic</th>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.194706</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.617548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.304957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shipping</th>\n",
       "      <td>0.019036</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.131509</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.596691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datapoints     feats   numeric  avg_corr  n_binary  \\\n",
       "anemia               0.016480  0.269565  0.137931  0.081748  0.333333   \n",
       "aus_rain             0.098939  1.000000  0.551724  0.286451  1.000000   \n",
       "campusrecruitment    0.000065  0.104348  0.172414  0.357938  0.148148   \n",
       "employability        0.001145  0.008696  0.000000  0.000000  0.092593   \n",
       "fraud                1.000000  0.173913  1.000000  0.236221  0.000000   \n",
       "loan                 0.008483  0.052174  0.241379  0.145074  0.074074   \n",
       "mobile_price         0.003205  0.147826  0.482759  0.034483  0.111111   \n",
       "stress               0.001622  0.104348  0.655172  0.568837  0.018519   \n",
       "student_testprep     0.001446  0.078261  0.103448  0.850244  0.138889   \n",
       "titanic              0.001251  0.026087  0.137931  0.194706  0.074074   \n",
       "wine                 0.000000  0.034783  0.448276  0.304957  0.000000   \n",
       "drug                 0.000039  0.000000  0.068966  0.063119  0.064815   \n",
       "shipping             0.019036  0.086957  0.206897  0.131509  0.120370   \n",
       "\n",
       "                   num_to_cat_ratio  classes  majority_fraction  \\\n",
       "anemia                     0.108108      4.0           0.386235   \n",
       "aus_rain                   0.146789      2.0           0.779741   \n",
       "campusrecruitment          0.294118      2.0           0.688372   \n",
       "employability              0.000000      2.0           0.687575   \n",
       "fraud                     29.000000      2.0           0.500000   \n",
       "loan                       0.777778      2.0           0.706000   \n",
       "mobile_price               1.076923      4.0           0.250000   \n",
       "stress                     6.333333      3.0           0.339091   \n",
       "student_testprep           0.187500      2.0           0.656000   \n",
       "titanic                    0.444444      2.0           0.617548   \n",
       "wine                      13.000000      3.0           0.398876   \n",
       "drug                       0.250000      5.0           0.455000   \n",
       "shipping                   0.428571      2.0           0.596691   \n",
       "\n",
       "                   best_classifier  \n",
       "anemia                         0.0  \n",
       "aus_rain                       0.0  \n",
       "campusrecruitment              0.0  \n",
       "employability                  0.0  \n",
       "fraud                          0.0  \n",
       "loan                           0.0  \n",
       "mobile_price                   0.0  \n",
       "stress                         0.0  \n",
       "student_testprep               0.0  \n",
       "titanic                        0.0  \n",
       "wine                           0.0  \n",
       "drug                           0.0  \n",
       "shipping                       0.0  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_feats.to_csv(\"metaset.csv\", index_label=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best classifier field is filled in after getting model results.\n",
    "\n",
    "0 -> logi\n",
    "\n",
    "1 -> knn\n",
    "\n",
    "2 -> ffn\n",
    "\n",
    "3 -> dt\n",
    "\n",
    "4 -> rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anemia</th>\n",
       "      <th>aus_rain</th>\n",
       "      <th>campusrecruitment</th>\n",
       "      <th>employability</th>\n",
       "      <th>fraud</th>\n",
       "      <th>loan</th>\n",
       "      <th>mobile_price</th>\n",
       "      <th>stress</th>\n",
       "      <th>student_testprep</th>\n",
       "      <th>titanic</th>\n",
       "      <th>wine</th>\n",
       "      <th>drug</th>\n",
       "      <th>shipping</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logi</th>\n",
       "      <td>0.998428</td>\n",
       "      <td>0.844825</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.916787</td>\n",
       "      <td>0.962645</td>\n",
       "      <td>0.742200</td>\n",
       "      <td>0.97350</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.797556</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.594951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.819213</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.933662</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>0.63300</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.808786</td>\n",
       "      <td>0.960794</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.607861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffn</th>\n",
       "      <td>0.996019</td>\n",
       "      <td>0.777810</td>\n",
       "      <td>0.860394</td>\n",
       "      <td>0.940865</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.743601</td>\n",
       "      <td>0.93349</td>\n",
       "      <td>0.882712</td>\n",
       "      <td>0.749015</td>\n",
       "      <td>0.820051</td>\n",
       "      <td>0.977589</td>\n",
       "      <td>0.974898</td>\n",
       "      <td>0.592951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817671</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.937276</td>\n",
       "      <td>0.993899</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.84550</td>\n",
       "      <td>0.889091</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.814429</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.617860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.802942</td>\n",
       "      <td>0.809302</td>\n",
       "      <td>0.927638</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.79300</td>\n",
       "      <td>0.878182</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.789710</td>\n",
       "      <td>0.955397</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.620675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         anemia  aus_rain  campusrecruitment  employability     fraud  \\\n",
       "model                                                                   \n",
       "logi   0.998428  0.844825           0.860465       0.916787  0.962645   \n",
       "knn    0.740413  0.819213           0.827907       0.933662  0.997031   \n",
       "ffn    0.996019  0.777810           0.860394       0.940865  0.999068   \n",
       "dt     1.000000  0.817671           0.813953       0.937276  0.993899   \n",
       "rf     0.981667  0.802942           0.809302       0.927638  0.999745   \n",
       "\n",
       "           loan  mobile_price    stress  student_testprep   titanic      wine  \\\n",
       "model                                                                           \n",
       "logi   0.742200       0.97350  0.881818          0.762000  0.797556  0.988889   \n",
       "knn    0.708200       0.63300  0.870000          0.681000  0.808786  0.960794   \n",
       "ffn    0.743601       0.93349  0.882712          0.749015  0.820051  0.977589   \n",
       "dt     0.745000       0.84550  0.889091          0.680000  0.814429  0.904762   \n",
       "rf     0.695000       0.79300  0.878182          0.663000  0.789710  0.955397   \n",
       "\n",
       "           drug  shipping  \n",
       "model                      \n",
       "logi   0.960000  0.594951  \n",
       "knn    0.900000  0.607861  \n",
       "ffn    0.974898  0.592951  \n",
       "dt     0.985000  0.617860  \n",
       "rf     0.980000  0.620675  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import exists\n",
    "\n",
    "if not exists(\"models.csv\"):\n",
    "\traise Exception(\"Please run the models notebook first\")\n",
    "\n",
    "models = pd.read_csv(\"models.csv\", index_col=\"model\")\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(models.columns):\n",
    "\ti = np.argmax(models[col])\n",
    "\tmeta_feats.loc[col, \"best_classifier\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_feats.to_csv(\"metaset.csv\", index_label=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datapoints</th>\n",
       "      <th>feats</th>\n",
       "      <th>numeric</th>\n",
       "      <th>avg_corr</th>\n",
       "      <th>n_binary</th>\n",
       "      <th>num_to_cat_ratio</th>\n",
       "      <th>classes</th>\n",
       "      <th>majority_fraction</th>\n",
       "      <th>best_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anemia</th>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.081748</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aus_rain</th>\n",
       "      <td>0.098939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.286451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.779741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campusrecruitment</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.357938</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employability</th>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.687575</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_price</th>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.147826</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stress</th>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.568837</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.339091</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_testprep</th>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.078261</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.850244</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titanic</th>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.194706</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.617548</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.304957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shipping</th>\n",
       "      <td>0.019036</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.131509</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.596691</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datapoints     feats   numeric  avg_corr  n_binary  \\\n",
       "anemia               0.016480  0.269565  0.137931  0.081748  0.333333   \n",
       "aus_rain             0.098939  1.000000  0.551724  0.286451  1.000000   \n",
       "campusrecruitment    0.000065  0.104348  0.172414  0.357938  0.148148   \n",
       "employability        0.001145  0.008696  0.000000  0.000000  0.092593   \n",
       "fraud                1.000000  0.173913  1.000000  0.236221  0.000000   \n",
       "loan                 0.008483  0.052174  0.241379  0.145074  0.074074   \n",
       "mobile_price         0.003205  0.147826  0.482759  0.034483  0.111111   \n",
       "stress               0.001622  0.104348  0.655172  0.568837  0.018519   \n",
       "student_testprep     0.001446  0.078261  0.103448  0.850244  0.138889   \n",
       "titanic              0.001251  0.026087  0.137931  0.194706  0.074074   \n",
       "wine                 0.000000  0.034783  0.448276  0.304957  0.000000   \n",
       "drug                 0.000039  0.000000  0.068966  0.063119  0.064815   \n",
       "shipping             0.019036  0.086957  0.206897  0.131509  0.120370   \n",
       "\n",
       "                   num_to_cat_ratio  classes  majority_fraction  \\\n",
       "anemia                     0.108108      4.0           0.386235   \n",
       "aus_rain                   0.146789      2.0           0.779741   \n",
       "campusrecruitment          0.294118      2.0           0.688372   \n",
       "employability              0.000000      2.0           0.687575   \n",
       "fraud                     29.000000      2.0           0.500000   \n",
       "loan                       0.777778      2.0           0.706000   \n",
       "mobile_price               1.076923      4.0           0.250000   \n",
       "stress                     6.333333      3.0           0.339091   \n",
       "student_testprep           0.187500      2.0           0.656000   \n",
       "titanic                    0.444444      2.0           0.617548   \n",
       "wine                      13.000000      3.0           0.398876   \n",
       "drug                       0.250000      5.0           0.455000   \n",
       "shipping                   0.428571      2.0           0.596691   \n",
       "\n",
       "                   best_classifier  \n",
       "anemia                         3.0  \n",
       "aus_rain                       0.0  \n",
       "campusrecruitment              0.0  \n",
       "employability                  2.0  \n",
       "fraud                          4.0  \n",
       "loan                           3.0  \n",
       "mobile_price                   0.0  \n",
       "stress                         3.0  \n",
       "student_testprep               0.0  \n",
       "titanic                        2.0  \n",
       "wine                           0.0  \n",
       "drug                           3.0  \n",
       "shipping                       4.0  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple notes, this is an extremely small dataset, and as mentioned in the proposal, I will most likely not be able to train a robust metaclassifier on this. However, we now move on to trying to accomplish this, nonetheless, in $\\verb|meta.ipynb|$.\n",
    "\n",
    "Also, it is the case here that kNN is not the best classifier for any dataset. This is expected, since the main draw of kNN is not its ability to produce highly accurate models, but the non-existent training cost. Ideally, I would have liked to have at least one example of kNN being the best classifier in the dataset, but I was not able to find such a set. It is fairly trivial to generate a set that kNN performs well on, but I did not choose to pursue this, as I thought it would bias the metaclassifier even further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
